{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve and store in a list of url_ending. For example: [egcu.org,libertyfirstcu.com, etc]\n",
    "#loop through this list to have a consolidated \"soup\" and get 2 separated files: details & reviews of all companies\n",
    "#connect to Postgre using Psycopg and store as tables there\n",
    "#set up cron job & automated scraping for new reviews daily, then append them to the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "atm_url = 'https://www.trustpilot.com/categories/atm'\n",
    "\n",
    "BASE_URL = \"https://www.trustpilot.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for html parser\n",
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    return BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_soup(atm_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to scrap all the URLs of business page\n",
    "\n",
    "def get_company_urls(soup_response):\n",
    "    company_urls = []\n",
    "    for a in soup.select(\"a[name='business-unit-card']\"):\n",
    "        url_subdirectory = a.attrs.get(\"href\")\n",
    "        company_urls.append(BASE_URL+url_subdirectory)\n",
    "    return company_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get the link of the next page button and scrap content on next page\n",
    "def get_next_page_url(soup_response):\n",
    "    return soup.select(\"a[name='pagination-button-next']\")[0].attrs.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap the list of company URLs\n",
    "company_urls = []\n",
    "\n",
    "while soup:\n",
    "    company_urls.extend(get_company_urls(soup))\n",
    "    next_page = get_next_page_url(soup)\n",
    "    if next_page:\n",
    "        soup = get_soup(BASE_URL+next_page)\n",
    "    else:\n",
    "        soup = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://www.trustpilot.com/review/acmeatm.cash',\n",
       " 'https://www.trustpilot.com/review/asicminersrig.com',\n",
       " 'https://www.trustpilot.com/review/asicminertech.com',\n",
       " 'https://www.trustpilot.com/review/cashexpressllc.com',\n",
       " 'https://www.trustpilot.com/review/coinhubatm.com',\n",
       " 'https://www.trustpilot.com/review/cryptobaseatm.com',\n",
       " 'https://www.trustpilot.com/review/cryptodispensers.com',\n",
       " 'https://www.trustpilot.com/review/egcu.org',\n",
       " 'https://www.trustpilot.com/review/heritagevalleyfcu.org',\n",
       " 'https://www.trustpilot.com/review/koinkryptatm.com',\n",
       " 'https://www.trustpilot.com/review/kryptominerstech.com',\n",
       " 'https://www.trustpilot.com/review/libertyfirstcu.com',\n",
       " 'https://www.trustpilot.com/review/meriwest.com',\n",
       " 'https://www.trustpilot.com/review/northone.com',\n",
       " 'https://www.trustpilot.com/review/pnc.com',\n",
       " 'https://www.trustpilot.com/review/slide2thrive.com',\n",
       " 'https://www.trustpilot.com/review/swadesh.co',\n",
       " 'https://www.trustpilot.com/review/thepaymenthq.com',\n",
       " 'https://www.trustpilot.com/review/vtsymorwvyj7k29pndy4jsc60x6oud.burpcollaborator.net',\n",
       " 'https://www.trustpilot.com/review/wpc.services',\n",
       " 'https://www.trustpilot.com/review/www.coin.cloud'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove duplicates in the URL list if any\n",
    "\n",
    "deduplicated_company_urls = set(company_urls)\n",
    "deduplicated_company_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish connection with PostgreSQL using psycopg2\n",
    "\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import psycopg2.extras as extras\n",
    "\n",
    "#Function to insert values into existing table\n",
    "def execute_values(conn, df, table):\n",
    "  \n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "  \n",
    "    col = ','.join(list(df.columns))\n",
    "    # SQL query to execute\n",
    "    query = \"INSERT INTO %s(%s) VALUES %%s\" % (table, col)\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"the dataframe is inserted\")\n",
    "    cursor.close()\n",
    "  \n",
    "  \n",
    "conn = psycopg2.connect(\n",
    "    database=\"atm_scraping\", user='postgres', password='postgres', host='127.0.0.1', port='5432'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#function to parse company page reviews: \n",
    "def parse_reviews(sub_soup):\n",
    "    data = []\n",
    "    name = sub_soup.find('span', attrs={'class': 'typography_display-s__qOjh6 typography_appearance-default__AAY17 title_displayName__TtDDM'}).text.strip()\n",
    "    reviews = sub_soup.find_all('div', attrs={'class': 'styles_cardWrapper__LcCPA styles_show__HUXRb styles_reviewCard__9HxJJ'})\n",
    "    for review in reviews:\n",
    "        review_stars = review.find_all('div', attrs={'class': 'star-rating_starRating__4rrcf star-rating_medium__iN6Ty'})\n",
    "        stars = [stars.find('img')['alt'].replace('Rated ', '').replace(' stars', '') for stars in review_stars]\n",
    "        review_dates = review.find('time', attrs={'class': '', 'data-service-review-date-time-ago': 'true'})\n",
    "        review_title = review.find('h2', attrs={'class': 'typography_heading-s__f7029 typography_appearance-default__AAY17'})\n",
    "        reviewer_name = review.find('span', attrs={'class': 'typography_heading-xxs__QKBS8 typography_appearance-default__AAY17'})\n",
    "        review_text = review.find('p', attrs={'class': 'typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn'})\n",
    "        experience_date = review.find('p', attrs={'class': 'typography_body-m__xgxZ_ typography_appearance-default__AAY17'})\n",
    "        review_reply_text = review.find('p', attrs={'class': 'typography_body-m__xgxZ_ typography_appearance-default__AAY17 styles_message__shHhX'})\n",
    "        reply_date_ = review.find('time', attrs={'class': 'typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_replyDate__Iem0_'})\n",
    "        star = stars[0] if stars else None\n",
    "        title = review_title.text.strip() if review_title else None\n",
    "        reviewer = reviewer_name.text.strip() if reviewer_name else None\n",
    "        text = review_text.text.strip() if review_text else None\n",
    "        experience = experience_date.text.split(':')[-1].strip() if experience_date else None\n",
    "        review_date = review_dates.get('datetime').split('T')[0].strip() if review_dates else None\n",
    "        reply_date = reply_date_.text.strip() if reply_date_ else None\n",
    "        reply_text = review_reply_text.text.strip() if review_reply_text else None\n",
    "        data.append([name, star, title, reviewer, text, experience, review_date, reply_date, reply_text])\n",
    "        columns = ['company_name','review_star', 'review_title', 'reviewer_name', 'review_text', 'experience_date', 'review_date', 'reply_date', 'reply_text']\n",
    "        global df_reviews \n",
    "        df_reviews = pd.DataFrame(data, columns=columns)\n",
    "    return df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "#scrap all reviews of all companies and upload them to Postgres\n",
    "#RUN ONLY ONCE, or delete data on table reviews before running this code again, otherwise it will appends dupplicated reviews to the table. \n",
    "for url in deduplicated_company_urls:\n",
    "    soup = get_soup(url)\n",
    "    while soup:\n",
    "        df = parse_reviews(soup)\n",
    "        next_page = get_next_page_url(soup)\n",
    "        if next_page:\n",
    "            soup = get_soup(BASE_URL+next_page)\n",
    "        else:\n",
    "            soup = None\n",
    "        execute_values(conn, df, 'reviews')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
